# -*- coding: utf-8 -*-
"""news_sentiment_collector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CVvDk2zwCPEbMKDJRS-KNfC4FpQxnHAb
"""

# Minimal per-index sentiment runner → saves into sp500/news, ftse100/news, ftse250/news

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
from pathlib import Path
from datetime import datetime, timezone
from sentiment_utils import fetch_and_score_sentiment  # from your module

BASE = Path("/content/drive/MyDrive/portfolio_data")

def run_for(master_csv: Path, out_dir: Path, limit: int|None = None,
            primary_hours=48, fallback_hours=7*24):
    out_dir.mkdir(parents=True, exist_ok=True)
    snap_dir = out_dir / "snapshots" / datetime.now(timezone.utc).date().isoformat()
    snap_dir.mkdir(parents=True, exist_ok=True)

    if not master_csv.exists():
        print(f"SKIP: {master_csv} not found")
        return

    df = pd.read_csv(master_csv)
    cols = {c.lower(): c for c in df.columns}
    tcol = cols.get("ticker") or "ticker"
    ncol = cols.get("name") or cols.get("company") or "name"
    uni = df[[tcol, ncol]].copy()
    uni.columns = ["Ticker","Name"]
    uni["Ticker"] = uni["Ticker"].astype(str).str.upper().str.strip()
    uni["Name"]   = uni["Name"].astype(str).str.strip()
    if limit: uni = uni.head(limit)

    agg, arts = fetch_and_score_sentiment(
        list(uni[["Ticker","Name"]].itertuples(index=False, name=None)),
        primary_hours=primary_hours,
        fallback_hours=fallback_hours,
        print_headlines=0,
    )

    now_utc = datetime.now(timezone.utc).isoformat()
    agg["LastUpdated"] = now_utc
    if not arts.empty:
        arts["IngestedAt"] = now_utc

    # write latest
    agg.to_csv(out_dir / "latest_aggregates.csv", index=False)
    arts.to_csv(out_dir / "latest_articles.csv", index=False)
    # daily snapshot
    agg.to_csv(snap_dir / "aggregates.csv", index=False)
    arts.to_csv(snap_dir / "articles.csv", index=False)

    print(f"Saved → {out_dir}/latest_aggregates.csv  | rows={len(agg)}")
    print(f"Saved → {out_dir}/latest_articles.csv    | rows={len(arts)}")
    print(f"Snapshot → {snap_dir}")

# ---- Run for each index ----
run_for(
    BASE / "sp500" / "sp500_master.csv",
    BASE / "sp500" / "news",
    # limit=50,  # uncomment while testing
)

run_for(
    BASE / "ftse100" / "ftse100_master.csv",
    BASE / "ftse100" / "news",
    # limit=50,
)

run_for(
    BASE / "ftse250" / "ftse250_master.csv",
    BASE / "ftse250" / "news",
    # limit=50,
)