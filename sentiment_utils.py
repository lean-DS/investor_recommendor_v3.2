# -*- coding: utf-8 -*-
"""sentiment_utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r4syBDwArVqLO13mtS5ges1YqkTbjfVs
"""

# sentiment_utils.py
# Minimal RSS â†’ FinBERT sentiment helper (no external APIs)
# Usage in app.py:
#   from sentiment_utils import fetch_and_score_sentiment
#   agg_df, articles_df = fetch_and_score_sentiment([("AAPL","Apple Inc.")])

from __future__ import annotations
import re, time, urllib.parse
from pathlib import Path
from datetime import datetime, timedelta, timezone
from typing import List, Tuple

import pandas as pd
import numpy as np
import feedparser

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline

# -------------------- Config (adjust in app if needed) --------------------
DEFAULT_LOCALE = dict(hl="en-GB", gl="GB", ceid="GB:en")
HALF_LIFE_DAYS = 7.0           # time-decay for daily aggregate
PER_TICKER_MAX_ROWS = 12       # cap headlines scored per ticker
POLITE_DELAY_SEC = 0.2         # small delay between tickers

# -------------------- Internals --------------------
_PIPE: TextClassificationPipeline | None = None

def _now_utc():
    return datetime.now(timezone.utc)

def _build_query(ticker: str, name: str) -> str:
    """Quoted company name + ticker + base (.L stripped), joined with OR."""
    base = ticker.replace(".L", "")
    nm = re.sub(r"[^\w\s\.\-&]", "", (name or "")).strip()
    parts = []
    if nm:
        parts.append(f"\"{nm}\"")
    parts.extend([ticker, base])
    # dedupe while preserving order
    parts = [p for i, p in enumerate(parts) if p and p not in parts[:i]]
    return " OR ".join(parts)

def _google_news_rss(query: str, since_hours: int, locale: dict = DEFAULT_LOCALE) -> pd.DataFrame:
    params = dict(q=query, **locale)
    url = "https://news.google.com/rss/search?" + urllib.parse.urlencode(
        params, quote_via=urllib.parse.quote_plus
    )
    d = feedparser.parse(url)
    rows = []
    cutoff = _now_utc() - timedelta(hours=since_hours)
    for e in d.entries:
        pub = getattr(e, "published_parsed", None)
        if not pub:
            continue
        pub_dt = datetime(*pub[:6], tzinfo=timezone.utc)
        if pub_dt < cutoff:
            continue
        title = getattr(e, "title", "") or ""
        link = getattr(e, "link", "") or ""
        rows.append({"title": title, "link": link, "published_at": pub_dt})
    return pd.DataFrame(rows)

def _get_pipe(model_name: str = "yiyanghkust/finbert-tone") -> TextClassificationPipeline:
    global _PIPE
    if _PIPE is not None:
        return _PIPE
    tok = AutoTokenizer.from_pretrained(model_name)
    mdl = AutoModelForSequenceClassification.from_pretrained(model_name)
    device_id = 0 if torch.cuda.is_available() else -1
    _PIPE = TextClassificationPipeline(
        model=mdl, tokenizer=tok,
        device=device_id,
        top_k=None,               # modern replacement for return_all_scores=True
        truncation=True, max_length=128, batch_size=32
    )
    return _PIPE

def _score_finbert(texts: List[str]) -> List[float]:
    if not texts:
        return []
    pipe = _get_pipe()
    preds = pipe(texts)  # list[list[{'label','score'}]]
    out = []
    for p in preds:
        d = {d['label'].lower(): d['score'] for d in p}
        pos = d.get('positive', 0.0); neg = d.get('negative', 0.0)
        s = (pos - neg + 1.0) / 2.0           # map to [0,1], 0.5 = neutral
        out.append(float(np.clip(s, 0.0, 1.0)))
    return out

def _aggregate_decay(df: pd.DataFrame, half_life_days: float = HALF_LIFE_DAYS) -> float:
    """Time-decayed mean of per-article scores; neutral (0.5) if empty."""
    if df.empty:
        return 0.5
    now = _now_utc()
    age_days = (now - df["published_at"]).dt.total_seconds() / 86400.0
    w = (0.5 ** (age_days / half_life_days)).clip(0, 1)
    s = (df["score"].clip(0.05, 0.95) * w).sum()
    denom = w.sum() if w.sum() > 0 else 1.0
    return float(s / denom)

# -------------------- Public API --------------------
def fetch_and_score_sentiment(
    tickers_names: List[Tuple[str, str]],
    primary_hours: int = 48,
    fallback_hours: int = 7*24,
    print_headlines: int = 0,
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Returns:
      aggregates_df: columns = [Ticker, Sentiment, Count]
      articles_df:   columns = [Ticker, published_at, title, score, link]
    Behavior:
      - Try Google News RSS for last `primary_hours`; if empty, `fallback_hours`.
      - If still empty, neutral 0.5.
      - Scores headlines with FinBERT; aggregates with time-decay.
    """
    all_agg, all_articles = [], []

    for ticker, name in tickers_names:
        try:
            q = _build_query(ticker, name)
            df = _google_news_rss(q, since_hours=primary_hours)
            if df.empty:
                df = _google_news_rss(q, since_hours=fallback_hours)

            if df.empty:
                all_agg.append({"Ticker": ticker, "Sentiment": 0.5, "Count": 0})
                continue

            df = df.sort_values("published_at", ascending=False).head(PER_TICKER_MAX_ROWS).reset_index(drop=True)
            df["score"] = _score_finbert(df["title"].tolist())
            agg = _aggregate_decay(df)

            if print_headlines > 0:
                print(f"{ticker} N={len(df)} agg={agg:.3f}")
                for _, r in df.head(print_headlines).iterrows():
                    print("   ", f"{r['score']:.3f}", r["title"][:110])

            df["Ticker"] = ticker
            all_articles.append(df[["Ticker","published_at","title","score","link"]])
            all_agg.append({"Ticker": ticker, "Sentiment": agg, "Count": len(df)})

            time.sleep(POLITE_DELAY_SEC)
        except Exception:
            all_agg.append({"Ticker": ticker, "Sentiment": 0.5, "Count": 0})

    agg = pd.DataFrame(all_agg).sort_values("Sentiment", ascending=False).reset_index(drop=True)
    art = pd.concat(all_articles, ignore_index=True) if all_articles else pd.DataFrame(
        columns=["Ticker","published_at","title","score","link"]
    )
    return agg, art